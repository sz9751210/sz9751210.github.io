<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>k8s | 艾倫的程式之旅</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Alan"><link rel=canonical href=https://sz9751210.github.io/tags/k8s/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://sz9751210.github.io/assets/profile/avatar.png><link rel=icon type=image/png sizes=16x16 href=https://sz9751210.github.io/assets/profile/avatar.png><link rel=icon type=image/png sizes=32x32 href=https://sz9751210.github.io/assets/profile/avatar.png><link rel=apple-touch-icon href=https://sz9751210.github.io/assets/profile/avatar.png><link rel=mask-icon href=https://sz9751210.github.io/assets/profile/avatar.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://sz9751210.github.io/tags/k8s/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-4RLTP9J7DY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-4RLTP9J7DY",{anonymize_ip:!1})}</script><meta property="og:title" content="k8s"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://sz9751210.github.io/tags/k8s/"><meta property="og:image" content="https://sz9751210.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://sz9751210.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="k8s"><meta name=twitter:description content="ExampleSite description"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8214206744217848" crossorigin=anonymous></script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://sz9751210.github.io/ accesskey=h title="Alan's BLOG (Alt + H)"><img src=https://sz9751210.github.io/assets/profile/avatar.png alt aria-label=logo height=35>Alan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://sz9751210.github.io/archives/ title=archives><span>archives</span></a></li><li><a href=https://sz9751210.github.io/posts/ title=posts><span>posts</span></a></li><li><a href=https://sz9751210.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://sz9751210.github.io/about/ title=about><span>about</span></a></li><li><a href=https://sz9751210.github.io/quote/ title=quote><span>quote</span></a></li><li><a href=https://sz9751210.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://sz9751210.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://sz9751210.github.io/tags/>Tags</a></div><h1>k8s
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes RBAC Overview：賦予安全與彈性的管理</h2></header><div class=entry-content><p>👨‍💻簡介 在當今的雲計算時代，容器化和微服務架構成為了重要趨勢。Kubernetes，作為領先的容器編排平台，提供了強大的功能來管理和部署應用程式。然而，隨著應用程式和用戶的增加，有效管理誰可以對 Kubernetes 集群執行何種操作變得至關重要。這裡，RBAC (Role-Based Access Control) 機制起到了關鍵作用。
🔰基礎介紹 什麼是 RBAC： RBAC 可以根據角色對用戶進行細粒度的權限管理。它基於三個主要概念：角色（Role）、角色綁定（RoleBinding）和主體（Subjects）。
角色 (Role) 和 ClusterRole：
角色 (Role)：定義了一組權限，這些權限表示對特定 Kubernetes 資源的操作，如建立、讀取、更新和刪除。 ClusterRole：與 Role 類似，但它適用於整個集群範圍，而不是單個命名空間。ClusterRole 可以用來賦予對集群級資源的訪問權限，或者跨所有命名空間的特定資源。 角色綁定 (RoleBinding) 和 ClusterRoleBinding：
角色綁定 (RoleBinding)：將角色的權限賦予給特定的主體。 ClusterRoleBinding：類似於 RoleBinding，但它將 ClusterRole 的權限賦予給整個集群的主體，而不是特定命名空間的主體。 主體 (Subjects)： 可以是用戶、群組或服務帳號。
為什麼要在 Kubernetes 中使用 RBAC？ 在 Kubernetes 中，RBAC 使得管理大型、多用戶的集群變得更為安全和方便。它確保了只有合適的用戶和服務能夠訪問關鍵的 Kubernetes 資源，從而降低了安全風險。
如何使用 RBAC 要開始使用 RBAC，首先要在 Kubernetes 集群中建立角色。例如，你可能有一個角色，只允許對 Pod 資源進行讀取操作。
kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: default name: pod-reader rules: - apiGroups: [""] resources: ["pods"] verbs: ["get", "list", "watch"] --- kind: RoleBinding apiVersion: rbac....</p></div><footer class=entry-footer><span title='2023-11-25 14:14:00 +0800 CST'>2023-11-25</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;212 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-rbac/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes RBAC Overview：賦予安全與彈性的管理" href=https://sz9751210.github.io/posts/k8s-rbac/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes Secret</h2></header><div class=entry-content><p>甚麼是secret 在 Kubernetes 裡，Secret 就像是一個保險箱，可以放你任何不想公開的東西。比如說密碼、API 金鑰、憑證等，這樣的資料可能會被放在 Pod 裡，但你可以用 Secret 來避免直接在應用程式的程式碼中暴露這些機密資料。 可以說 Secret 就像是 ConfigMap 的一個好朋友，但更專門用來保護機密資料的地方。
為甚麼需要secret 最主要的用意是保護你的敏感資訊，不讓它們在 Pod 或容器中以明文流傳。這樣可以讓我們的應用程式變得更安全，減少機密資訊外洩的風險。還能讓你的秘密資料在不同 Pod 之間分享，並且保有安全性。
何時使用secret 保存必要應用程式的憑證，如 TLS 證書，以確保安全通信。 儲存應用程式所需的金鑰，包括外部服務的 API 金鑰，確保安全連接。 保管敏感的環境變數，如資料庫密碼等機密驗證資訊，維護應用程式安全性。 安全儲存驗證資訊，如 OAuth 令牌，用於與其他應用程式進行安全交互。 維持隱私的配置設定，如設定文件、金鑰路徑等，確保敏感資訊不外洩。 secret的類型有哪些 內建類型 用途 Opaque 使用者定義的任意資料 kubernetes.io/service-account-token 服務帳戶令牌 kubernetes.io/dockercfg ~/.dockercfg 檔案的序列化形式 kubernetes.io/dockerconfigjson ~/.docker/config.json 檔案的序列化形式 kubernetes.io/basic-auth 用於基本身份驗證的憑證 kubernetes.io/ssh-auth 用於 SSH 身份驗證的憑證 kubernetes.io/tls 用於 TLS 客戶端或伺服器端的資料 bootstrap.kubernetes.io/token 啟動引導令牌資料 如何撰寫使用secret 建立secret 聲明式 apiVersion: v1 kind: Secret metadata: name: my-secret data: username: YWRtaW4= # Base64 編碼的 "admin" password: c2VjcmV0cGFzc3dvcmQ= # Base64 編碼的 "secretpassword" 宣告式 從命令行傳遞資訊建立secret kubectl create secret generic my-secret --from-literal=username=admin --from-literal=password=secretpassword 從檔案建立secret kubectl create secret generic my-secret --from-file=path/to/username....</p></div><footer class=entry-footer><span title='2023-08-17 20:52:00 +0800 CST'>2023-08-17</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;265 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-secret/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes Secret" href=https://sz9751210.github.io/posts/k8s-secret/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes憑證過期：Unable To Connect To The Server: X509: Certificate Has Expired Or Is Not Yet Valid</h2></header><div class=entry-content><p>👨‍💻簡介 今天早上在下kubectl get pods時，突然跳出了以下錯誤
warning Unable to connect to the server: x509: certificate has expired or is not yet valid 下了kubeadm alpha certs check-expiration之後才發現原來是憑證過期 因此紀錄一下解決過程
Information environment NAME="CentOS Linux" VERSION="7 (Core)" ID="centos" ID_LIKE="rhel fedora" VERSION_ID="7" PRETTY_NAME="CentOS Linux 7 (Core)" ANSI_COLOR="0;31" CPE_NAME="cpe:/o:centos:centos:7" HOME_URL="https://www.centos.org/" BUG_REPORT_URL="https://bugs.centos.org/" CENTOS_MANTISBT_PROJECT="CentOS-7" CENTOS_MANTISBT_PROJECT_VERSION="7" REDHAT_SUPPORT_PRODUCT="centos" REDHAT_SUPPORT_PRODUCT_VERSION="7" docker version Client: Version: 1.13.1 API version: 1.26 Package version: docker-1.13.1-162.git64e9980.el7.centos.x86_64 Go version: go1.10.3 Git commit: 64e9980/1.13.1 Built: Wed Jul 1 14:56:42 2020 OS/Arch: linux/amd64 Server: Version: 1....</p></div><footer class=entry-footer><span title='2023-07-27 13:56:00 +0800 CST'>2023-07-27</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;759 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-certificate-expired/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes憑證過期：Unable To Connect To The Server: X509: Certificate Has Expired Or Is Not Yet Valid" href=https://sz9751210.github.io/posts/k8s-certificate-expired/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes ConfigMap</h2></header><div class=entry-content><p>甚麼是Kubernetes ConfigMap ConfigMap主要功用是儲存我們服務的設定，這使得我們可以將我們的應用服務具備可移植性，當需要相對應的環境參數時，只需要修改ConfigMap，而不需要去更動到image即可更換成新的部屬環境。
為甚麼需要ConfigMap 最主要的用意是共享相同設定。在初期開發時可能只有幾個服務而直接把設定檔寫死，如果在後期變成微服務的架構下，上百個服務都有自己的設定檔在日後維護下會顯得麻煩，因此有了ConfigMap的出現，幫助我們將環境變數與容器鏡像解藕，便於修改應用設定，減少維護成本
何時使用ConfigMap，ConfigMap使用場景 ConfigMap通常儲存服務的環境變數、命令行參數、配置文件等非機密資料，使用場景有設定檔與容器鏡像分離、多環境支持、共享設定、動態設定更新等等
ConfigMap有哪些特點 解藕配置 -> 將服務的設定檔與容器鏡像分離，使服務在不重新建置新的容器鏡像可修改和管理設定檔，提高容器鏡像的通用性和靈活性 靈活性 -> ConfigMap支援多種格式，並且需要時可動態更新設定，無須重啟服務或重新佈署容器 共享設定 -> ConfigMap允許多個Pod共享同一份設定檔，確保了使用相同設定檔的Pod的一致性，提高設定的可維護性和一致性 集中管理 -> ConfigMap在K8s集群中可以集中管理所有的ConfigMap，不需要逐個修改Pod的設定 如何撰寫使用ConfigMap 創建ConfigMap Imperative(命令式) --from-literal kubectl create configMap myconfig --from-literal=k1=v1 --from-literal=k2=v2 --from-file kubectl create configMap myconfigfromkey --from-file=fromfilekey=from-key Declarative(聲明式) apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very 使用ConfigMap 使用ConfigMap定義容器環境變量 從單一ConfigMap定義容器環境變量 ConfigMap ## create configmap kubectl create configmap special-config --from-literal=special.how=very Pod apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: registry....</p></div><footer class=entry-footer><span title='2023-07-18 20:40:00 +0800 CST'>2023-07-18</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;709 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-configmap/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes ConfigMap" href=https://sz9751210.github.io/posts/k8s-configmap/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes Deployment：Overview</h2></header><div class=entry-content><p>什麼是 Kubernetes Deployment? 一樣先來個官網解說
A Deployment provides declarative updates for Pods and ReplicaSets.
You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.
跟ReplicaSet不同，Deployment的工作主要是為 pod & replicaset 提供了一個宣告式的設定 & 更新方式，透過定義 desired status，Deployment controller 會在所謂的 controlled rate 下達到使用者所期望的狀態，這些機制是由 k8s 自動化完成，因此官方建議應該透過 Deployment 來佈署 pod & replicaset。...</p></div><footer class=entry-footer><span title='2023-05-30 15:53:00 +0800 CST'>2023-05-30</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;453 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-deploy/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes Deployment：Overview" href=https://sz9751210.github.io/posts/k8s-deploy/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes ReplicaSet：Overview</h2></header><div class=entry-content><p>什麼是 Kubernetes ReplicaSet? 先來個官網解說
A ReplicaSet’s purpose is to maintain a stable set of replica Pods running at any given time. As such, it is often used to guarantee the availability of a specified number of identical Pods.
根據上述描述，Replica Set主要的作用是確保始終都有一定數量的相同Pod可用，保證服務的高可用性。
Kubernetes RS是Kubernetes中的一種控制器，主要用於管理Pod的複製和伸縮，確保Pod的數量。RS具有以下幾種特性 自動管理pod的副本數量：確保指定數量的Pod跟使用者所期望的一致(desired status)，如果發生故障或需要擴展，它會自動創建或刪除Pod。 確保Pod的健康狀態：如果發生故障會對失敗的Pod進行重新調度 創建Pod的Template：當需要新的Pod時會根據定義的Pod Template創建 為什麼需要Replicaset? 在Kubernetes集群中，Pod的管理對於系統的可靠性和彈性至關重要。如果一個Pod發生故障，RS會自動創建一個新的Pod來代替它，確保服務繼續運行。同時，當服務需要擴展以滿足流量增加時，Kubernetes RS也可以自動創建額外的Pod。因此RS解決了以下問題：
確保服務的高可用性和可靠性：RS可以自動維護一定數量的Pod，確保服務在Pod失敗時仍然可以正常運行。 方便服務的擴展：使用RS可以根據需求調整Pod的副本數量，實現服務的快速擴展。 簡化服務管理：RS可以自動調整Pod的數量，減少手動管理的工作量。 Kubernetes Replicaset是如何運作的？ 定義RS，指定所需的Pod副本數量和Pod Template，創建後，ReplicaSet使用定義好的Pod Template創建Pod，並開始監控每個Pod的狀態以及數量是否與定義的一致(desired status)，如果低於指定副本數則會創建Pod，高於指定副本數則會刪除Pod，當Pod被意外刪除時會創建新的Pod來做替代。
什麼時候使用Replicaset？ 使用RS通常適用於以下情況：
需要確保一定數量的Pod正在運行，以保持服務的可用性和可靠性。 需要能夠自動擴展和縮小Pod數量，以應對流量變化和其他需求。 希望能夠自動替換發生故障的Pod，以確保服務的連續運行。 需要管理一個服務的多個Pod，並且希望使用Kubernetes提供的自動化功能，例如調度、網路配置和負載平衡。 Kubernetes Replicaset有哪些特性？ 高可用性：RS的目的是維護一個穩定的Pod副本集，確保始終有一定數量的相同Pod可用，從而保證服務的高可用性。
健康檢查和自動恢復：ReplicaSet可以通過定期檢查Pod副本的健康狀態來確保服務始終運行。當Pod故障或被刪除時，ReplicaSet會自動創建新的Pod來代替故障的Pod，確保服務的可用性及穩定性。
自動擴縮：RS會監視Pod副本數量，並自動創建或刪除Pod副本以確保Pod副本數量達到指定的數量。使服務可以自動擴展和縮放，以應對不同的負載。...</p></div><footer class=entry-footer><span title='2023-03-06 11:52:00 +0800 CST'>2023-03-06</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;194 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-rs/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes ReplicaSet：Overview" href=https://sz9751210.github.io/posts/k8s-rs/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes Service：Overview</h2></header><div class=entry-content><p>什麼是Kubernetes Service？ 先來個官網的解說
A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them.
白話文就是，訪問Pod用的一個Component。ＸＤ
Kubernetes Service是個抽象概念，通過Service，當我們的Pod創建好後，定義訪問它們的策略，該如何去訪問一群相同邏輯的Pod，給Pod提供一組穩定的IP或是Port。
因此也可以把Service當作是一種掛在一群運行相同應用程式前面的LoadBalancer，詳見下圖。
圖片來源
為什麼需要Kubernetes Service？ 因為在Kubernetes集群中，Pod的IP地址是不穩定的，可能因為重新調度或重啟Container而改變了IP。為了使其他應用程式能夠穩定地訪問Pod，需要使用Kubernetes Service。
Kubernetes Service是如何工作的？ 當Pod啟動時，它們會自動註冊到Kubernetes集群中的一個服務發現機制中，例如Kubernetes DNS或etcd。Service會監聽這個服務發現機制，並根據Label Selector選擇要提供服務的Pod。
當其他應用程式需要訪問Pod時，它們可以通過Service的IP和Port進行訪問，Service會將請求根據Label Selector轉發到選定的Pod。由於Service的IP和端口是穩定的，即使Pod的IP地址發生變化，其他應用程式依然可以一直使用相同的IP和Port訪問該Pod。
圖片來源
Kubernetes Service的類型有哪些？ Kubernetes Service有以下四種類型：
ClusterIP: 在Kubernetes集群內部使用，通常用於應用程式的內部通訊。 NodePort: 將Pod暴露到Kubernetes集群的外部，並使用Node的IP和一個Static Port進行訪問。 LoadBalancer: LoadBalancer是ClusterIP和NodePort的一種擴展。在公有雲上使用，使用雲供應商提供的LoadBalancer將流量轉發到Service中的Pod。 ExternalName: 允許服務將外部DNS名稱映射到Kubernetes集群內部的svc名稱上。這樣可以在不修改應用程式代碼的情況下實現外部服務的訪問。 圖片來源 Kubernetes Service有哪些功能？ Kubernetes Service具有以下功能：
透明地將請求轉發到Pod中，無需修改應用程式代碼。 提供負載均衡，分散流量到多個Pod中。 支持多種協議，例如TCP、UDP和HTTP。 可以設置Session Affinity，將請求路由到相同的Pod。 可以進行Port轉發，將請求轉發到Pod中的不同Port。 支持跨命名空間訪問。 如何創建和管理Kubernetes Service： 要創建 Kubernetes Service，可以使用以下兩種方式： 宣告式(Declarative) kind: Service apiVersion: v1 metadata: name: my-service spec: # type 一共有四種(ClusterIP, NodePort, LoadBalancer, ExternalName)，預設是 ClusterIP type: ClusterIP # 選擇帶有 "app=MyApp" 的 pod selector: app: MyApp # Service 實際對外服務的設定 ports: # 使用的協定與port，預設為TCP - protocol: TCP port: 80 # Pod對外開放的port，如無設定，預設與spec....</p></div><footer class=entry-footer><span title='2023-03-03 10:28:00 +0800 CST'>2023-03-03</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;188 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-svc/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes Service：Overview" href=https://sz9751210.github.io/posts/k8s-svc/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>Kubernetes Pod：Overview</h2></header><div class=entry-content><p>Kubernetes是現代應用程序開發和部署的重要技術，而Pod是Kubernetes中最小的部署單位。Pod是一個或多個container的集合，它們共享一個網路命名空間和一個網路接口。Pod不僅提供了一個簡單而強大的container環境，還可以用於實現多種container編排方案，例如負載平衡、數據管理、多container協作等。
本文將深入探討Kubernetes中的Pod，介紹Pod的基本概念、設計原則和實現方式，以及與其他資源的關係。您將學習如何創建和配置Pod，如何使用Kubernetes管理Pod，以及如何通過Pod實現高效、彈性和可靠的應用程序部署。
什麼是Kubernetes Pod Kubernetes Pod是Kubernetes集群中最小的部署單位。一個Pod可以包含一個或多個container，這些container共享相同的網路和儲存空間。Pod提供了一個環境，讓container可以協同工作，形成一個應用程序。
Pod的結構和特性 Pod包含以下元素：
共享網路空間 (Networking)：Pod 中的所有container共享相同的網路空間，可以在container之間通過 localhost 進行通信。 共享儲存空間 (Shared Storage)：Pod 中的所有container共享相同的儲存空間，可以在container之間共享文件、環境變量等。 容器 (Containers)：Pod 中可以包含一個或多個container，這些container可以共享同一個網路和儲存空間，方便container之間的互相協作。 存活和重啟策略 (Liveness and Restart Policy)：Pod 的存活策略指定了在容器出現異常情況時，Kubernetes 如何應對，如重新啟動 container 或者將其標記為失敗。Pod 的重啟策略則指定了當 Pod 中的所有 container 都停止運行時，Kubernetes 如何進行重啟。 元數據 (Metadata)：Pod 中包含一些元數據，如 Pod 名稱、命名空間、標籤等，這些元數據可以用於管理和監控 Pod。 Pod的特性包括：
生命週期短暫 可以擁有多個container 具有唯一的IP地址 具有獨立的儲存空間 具有網路隔離 如何創建和管理Pod 要創建 Kubernetes Pod，可以使用以下兩種方式： 宣告式（Declarative）：使用 YAML 或 JSON 格式的文件來定義 Pod 的結構、元資料和規格，包括 Pod 名稱、container image、資源限制、網路設定等。 apiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: nginx-container image: nginx:latest ports: - containerPort: 80 接著使用kubectl創建pod...</p></div><footer class=entry-footer><span title='2023-03-01 20:43:00 +0800 CST'>2023-03-01</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;365 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-pod/cover.png alt></figure><a class=entry-link aria-label="post link to Kubernetes Pod：Overview" href=https://sz9751210.github.io/posts/k8s-pod/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>k8s-reloader</h2></header><div class=entry-content><p>👨‍💻簡介 有時候修改掛載的config檔，無法即時更新，需要重啟pod才會生效，為了解決這個問題，k8s-reloader因此而誕生，透過觀察掛載的configmap或是secret的變化自動對掛載的物件做滾動更新。
以下為在minikube環境下，透過掛載nginx-config檔並搭配reloader這個插件進行熱部署。
🔗github-repo : stakater/Reloader: A Kubernetes controller to watch changes in ConfigMap and Secrets and do rolling upgrades on Pods with their associated Deployment, StatefulSet, DaemonSet and DeploymentConfig – [✩Star] if you’re using it! (github.com) 🔰基礎介紹 運作原理 Reloader偵測所有資源變化，對有變化的資源使用SHA1計算資源的哈西值 Reloader查看是否有設定相關的annotation，並查看有設定annotation資源的特殊環境變量 對有設定annotation的資源比對其哈希值，如果環境變量中哈希值不同，則更新環境變量，如果環境變量不存在，則創建一個 環境變量名稱 ConfigMap：STAKATER_{configmap_name}_CONFIGMAP ，比如 ConfigMap 的名稱為 foo，則生成的環境變量的名稱為：STAKATER_FOO_CONFIGMAP。 Secret：STAKATER_{secret_name}_SECRET ，比如 Secret 的名稱為 foo，則生成的環境變量的名稱為：STAKATER_FOO_SECRET。 環境變量的值 使用 SHA1 計算的 ConfigMap 或者 Secret 的哈希值。
版本需求 k8s版本需 >= 1.9
安裝方式 使用Manifests安裝 kubectl apply -f https://raw....</p></div><footer class=entry-footer><span title='2022-11-11 15:05:00 +0800 CST'>2022-11-11</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;373 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-reloader/cover.png alt></figure><a class=entry-link aria-label="post link to k8s-reloader" href=https://sz9751210.github.io/posts/k8s-reloader/></a></article><article class="post-entry tag-entry"><div class=post-info><header class=entry-header><h2>K8S-monitor</h2></header><div class=entry-content><p>📔心得 之前都介紹docker監控container，這次來點不一樣的，直接裝在k8s裡面去監控pod的一些指標。
基本的指標像是cpu, mem, pod數量, node數量等等，都能透過kube-state-metrics完成，而如果想要監控一些流量的指標，像是tcp連線數，tw數等，則是需要另外在服務的pod裡另外寫node-exporter的container，組成side-car的形式，讓exporter將指標送往prometheus。
在撰寫的過程，遇到比較大的難題是prometheus的config檔撰寫，一開始打算使用docker-compose的方式起monitor服務，然後去call k8s cluster取得相關指標，但常常call不到服務，可能是因為minikube的關係，在本地也跑docker，最後改成直接安裝在k8s裡面，另外建立一個namespace放監控相關的服務，有機會在測試kind以及k3s。
demo用的deploy使用skaffold這本地開發k8s的神器，搭配kustomize可讓我依據所需測試的環境下去做自動佈署，有機會再另外介紹這工具。
之後預計會再新增prometheus adapter，讓我的prometheus metrics可以成為我hpa的擴縮判斷，因為基本的hpa指標只有cpu以及mem，如果可以依照網路流量變大，幫我擴展pod，當流量變小時幫我縮pod，讓我能自定義指標，相信使用k8s的效益會更大。
🔗詳細專案位置 –> https://github.com/sz9751210/k8s-monitor
...</p></div><footer class=entry-footer><span title='2022-10-17 10:41:00 +0000 UTC'>2022-10-17</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;72 words&nbsp;·&nbsp;Alan</footer></div><figure class=entry-cover><img loading=lazy src=https://sz9751210.github.io/assets/k8s-monitor/cover.png alt></figure><a class=entry-link aria-label="post link to K8S-monitor" href=https://sz9751210.github.io/posts/k8s-monitor/></a></article></main><footer class=footer><span>&copy; 2023 <a href=https://sz9751210.github.io/>艾倫的程式之旅</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let detail=document.getElementsByClassName("details");details=[].slice.call(detail);for(let e=0;e<details.length;e++){let t=details[e];const n=t.getElementsByClassName("details-summary")[0];n&&n.addEventListener("click",()=>{t.classList.toggle("open")},!1)}</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>